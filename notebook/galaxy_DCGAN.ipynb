{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d29dfd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# modify from https://pytorch.org/tutorials/beginner/dcgan_faces_tutorial.html\n",
    "%matplotlib inline\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from PIL import Image\n",
    "from torchvision.datasets import DatasetFolder\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm.notebook import tqdm as tqdm\n",
    "import torch.nn.functional as F\n",
    "from torchsampler import ImbalancedDatasetSampler\n",
    "import torchvision.utils as vutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d280e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameter\n",
    "batch_size = 32\n",
    "lr_generator = 0.0001\n",
    "lr_discriminator = 0.0001\n",
    "in_img = 196608\n",
    "epochs = 100\n",
    "random.seed(999)\n",
    "torch.manual_seed(999)\n",
    "\n",
    "g_hidden = 64\n",
    "d_hidden = 64\n",
    "input_size = 100\n",
    "image_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d128c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_on_gpu = torch.cuda.is_available()\n",
    "if not train_on_gpu:\n",
    "    print(\"CUDA is not available\")\n",
    "else:\n",
    "    print(\"CUDA is available\")\n",
    "device = 'cuda' if train_on_gpu else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b391c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image_path = \"/home/chisc/workspace/wuzhenrong/galaxy/three_final/train/gans/\"\n",
    "train_trans = transforms.Compose([transforms.Resize(image_size),\n",
    "                                  transforms.CenterCrop(image_size),\n",
    "                                  transforms.ToTensor(),\n",
    "                                  transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),])\n",
    "train_data = ImageFolder(train_image_path, transform = train_trans)\n",
    "train_loader = DataLoader(train_data, pin_memory = True, batch_size = batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca374c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(imgs):\n",
    "    imgs = torchvision.utils.make_grid(imgs, padding=2, normalize=True)\n",
    "    npimgs = imgs.numpy()\n",
    "    plt.figure(figsize=(8,8))\n",
    "    plt.imshow(np.transpose(npimgs, (1,2,0)))\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d90b4a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "img, label = next(iter(train_loader))\n",
    "# imshow(img)\n",
    "# plt.xticks([])\n",
    "# plt.yticks([])\n",
    "imshow(img)\n",
    "# plt.imshow(np.transpose(vutils.make_grid(real_batch[0].to(device)[:64], padding=2, normalize=True).cpu(),(1,2,0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b289588",
   "metadata": {},
   "outputs": [],
   "source": [
    "## all model weights shall be randomly initialized from a Normal distribution with mean=0, stdev=0.02.\n",
    "def weight_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1: ## convolutional layer\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1: ## batchnormal layer\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e30acd01",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.ConvTranspose2d(input_size, g_hidden * 8, 4, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(g_hidden * 8),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf*8) x 4 x 4\n",
    "            nn.ConvTranspose2d(g_hidden * 8, g_hidden * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(g_hidden * 4),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf*4) x 8 x 8\n",
    "            nn.ConvTranspose2d(g_hidden * 4, g_hidden * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(g_hidden * 2),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf*2) x 16 x 16\n",
    "            nn.ConvTranspose2d(g_hidden * 2, g_hidden, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(g_hidden),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf) x 32 x 32\n",
    "            nn.ConvTranspose2d(g_hidden, 3, 4, 2, 1, bias=False),\n",
    "            nn.Tanh()\n",
    "            # state size. (nc) x 64 x 64\n",
    "        )\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        return self.main(inputs)\n",
    "    \n",
    "    \n",
    "    \n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            # input is (nc) x 64 x 64\n",
    "            nn.Conv2d(3, d_hidden, 4, 2, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf) x 32 x 32\n",
    "            nn.Conv2d(d_hidden, d_hidden * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(d_hidden * 2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf*2) x 16 x 16\n",
    "            nn.Conv2d(d_hidden * 2, d_hidden * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(d_hidden * 4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf*4) x 8 x 8\n",
    "            nn.Conv2d(d_hidden * 4, d_hidden * 8, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(d_hidden * 8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf*8) x 4 x 4\n",
    "            nn.Conv2d(d_hidden * 8, 1, 4, 1, 0, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        return self.main(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "491191e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "G = Generator().to(device)\n",
    "D = Discriminator().to(device)\n",
    "G.apply(weight_init)\n",
    "D.apply(weight_init)\n",
    "print(G)\n",
    "print(D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd60bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize BCELoss function\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "# Create batch of latent vectors that we will use to visualize\n",
    "#  the progression of the generator\n",
    "fixed_noise = torch.randn(64, 100, 1, 1, device=device)\n",
    "\n",
    "# Establish convention for real and fake labels during training\n",
    "real_label = 1.\n",
    "fake_label = 0.\n",
    "\n",
    "# Setup Adam optimizers for both G and D\n",
    "d_opt = optim.Adam(D.parameters(), lr=lr_generator, betas=(0.5, 0.999))\n",
    "g_opt = optim.Adam(G.parameters(), lr=lr_discriminator, betas=(0.5, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb4dad2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "img_list = []\n",
    "G_losses = []\n",
    "D_losses = []\n",
    "\n",
    "## Training\n",
    "for epoch in range(epochs):\n",
    "    g_total_loss = 0.0\n",
    "    d_total_loss = 0.0\n",
    "    for idx, data in tqdm(enumerate(train_loader)):\n",
    "        # update d network\n",
    "        D.zero_grad()\n",
    "        real = data[0].to(device)\n",
    "        b_size = real.size(0)\n",
    "        label = torch.full((b_size,), real_label, device=device)\n",
    "        output = D(real).view(-1)\n",
    "#         print(output.shape)\n",
    "#         print('label:', label.shape)\n",
    "        d_real_loss = criterion(output, label)\n",
    "        d_real_loss.backward()\n",
    "        D_x = output.mean().item()\n",
    "        \n",
    "        noise = torch.randn(b_size, 100, 1, 1, device=device)\n",
    "        fake = G(noise)\n",
    "        label.fill_(fake_label)\n",
    "        output = D(fake.detach()).view(-1)\n",
    "        \n",
    "        d_fake_loss = criterion(output, label)\n",
    "        d_fake_loss.backward()\n",
    "        \n",
    "        D_G_z1 = output.mean().item()\n",
    "        d_loss = d_real_loss + d_fake_loss\n",
    "        d_opt.step()\n",
    "        \n",
    "        # update g network\n",
    "        G.zero_grad()\n",
    "        label.fill_(real_label)\n",
    "        output = D(fake).view(-1)\n",
    "        g_loss = criterion(output, label)\n",
    "        g_loss.backward()\n",
    "        D_G_z2 = output.mean().item()\n",
    "        g_opt.step()\n",
    "        \n",
    "        # Output training stats\n",
    "        if idx % 50 == 0:\n",
    "            print('[%d/%d][%d/%d]\\tLoss_D: %.4f\\tLoss_G: %.4f\\tD(x): %.4f\\tD(G(z)): %.4f / %.4f' % (epoch, epochs, idx, len(train_loader), d_loss.item(), g_loss.item(), D_x, D_G_z1, D_G_z2))\n",
    "            samples = G(noise).detach()\n",
    "            samples = samples.view(samples.size(0), 3, 64, 64).cpu()\n",
    "            imshow(samples)\n",
    "        G_losses.append(g_loss.item())\n",
    "        D_losses.append(d_loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb0fab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(G, 'S_type_generator.pkl')\n",
    "torch.save(D, 'S_type_discriminator.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a96321",
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = torch.randn(100, 100, 1, 1, device=device)\n",
    "samples = G(noise).detach()\n",
    "samples = samples.view(samples.size(0), 3, 64, 64).cpu()\n",
    "imshow(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9713eb2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
