{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9f9145e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from PIL import Image\n",
    "from torch.utils.data.sampler import WeightedRandomSampler\n",
    "from torchvision.datasets import DatasetFolder\n",
    "import torchvision\n",
    "from tqdm.notebook import tqdm as tqdm\n",
    "from torchsampler import ImbalancedDatasetSampler\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import torch.nn.functional as F\n",
    "import copy\n",
    "import os\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from PIL import ImageFile\n",
    "import torch.autograd as autograd\n",
    "import torchvision.transforms as transforms\n",
    "from pytorch_grad_cam import GradCAM\n",
    "from pytorch_grad_cam.utils.image import show_cam_on_image, deprocess_image,  preprocess_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0e5f8da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available!\n"
     ]
    }
   ],
   "source": [
    "train_on_gpu = torch.cuda.is_available()\n",
    "if not train_on_gpu:\n",
    "    print('CUDA is not available.')\n",
    "else:\n",
    "    print('CUDA is available!')\n",
    "device = \"cuda\" if train_on_gpu else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d957a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "supervised_path = \"/home/chisc/workspace/wuzhenrong/galaxy/eight_type/train/\"\n",
    "val_image_path = \"/home/chisc/workspace/wuzhenrong/galaxy/eight_type/validation/\"\n",
    "test_image_path = \"/home/chisc/workspace/wuzhenrong/galaxy/eight_type/test/\"\n",
    "batch_size = 16\n",
    "train_trans = transforms.Compose([\n",
    "#                                   transforms.RandomHorizontalFlip(),\n",
    "#                                   transforms.RandomRotation((-30, 30)),\n",
    "#                                   transforms.Resize((256, 256)),\n",
    "#                                   transforms.RandomCrop(size=(100, 100)),\n",
    "                                  transforms.Resize((256, 256)),\n",
    "#                                   transforms.CenterCrop(200),\n",
    "#                                   transforms.Resize((256, 256)),\n",
    "#                                   transforms.Resize((255, 255)),\n",
    "#                                   transforms.GaussianBlur(7,3),\n",
    "#                                   transforms.ColorJitter(contrast=0.8),\n",
    "                                  transforms.ToTensor()])\n",
    "train_data = ImageFolder(supervised_path, transform=train_trans)\n",
    "train_loader = DataLoader(train_data, pin_memory=True, batch_size=batch_size, sampler=ImbalancedDatasetSampler(train_data))\n",
    "\n",
    "val_trans = transforms.Compose([transforms.Resize((256, 256)),transforms.ToTensor()])\n",
    "val_data = ImageFolder(val_image_path, transform = val_trans)\n",
    "val_loader = DataLoader(val_data, shuffle = True)\n",
    "\n",
    "test_trans = transforms.Compose([transforms.Resize((256, 256)),transforms.ToTensor()])\n",
    "test_data = ImageFolder(test_image_path, transform = test_trans)\n",
    "test_loader = DataLoader(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "79d29bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = torchvision.models.vgg16(pretrained=False)\n",
    "model = torch.load('E_I_S_new.pkl')\n",
    "model = model.to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2f8eb587",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Resnet18 and 50: model.layer4[-1]\n",
    "# VGG and densenet161: model.features[-1]\n",
    "# mnasnet1_0: model.layers[-1]\n",
    "# ViT: model.blocks[-1].norm1\n",
    "# SwinT: model.layers[-1].blocks[-1].norm1\n",
    "\n",
    "target_layer = model.features[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8ad9bc18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/chisc/workspace/wuzhenrong/galaxy/eight_type/test/E/PGC0002149.png\n",
      "/home/chisc/workspace/wuzhenrong/galaxy/eight_type/test/S0/PGC0000243.png\n",
      "/home/chisc/workspace/wuzhenrong/galaxy/eight_type/test/Sa/PGC0000639.png\n",
      "/home/chisc/workspace/wuzhenrong/galaxy/eight_type/test/Sb/PGC0002440.png\n",
      "/home/chisc/workspace/wuzhenrong/galaxy/eight_type/test/SBa/PGC0000635.png\n",
      "/home/chisc/workspace/wuzhenrong/galaxy/eight_type/test/SBb/PGC0010726.png\n",
      "/home/chisc/workspace/wuzhenrong/galaxy/eight_type/test/SBc/PGC0006826.png\n",
      "/home/chisc/workspace/wuzhenrong/galaxy/eight_type/test/Sc/PGC0001933.png\n"
     ]
    }
   ],
   "source": [
    "path = [\"E/PGC0002149\", \"S0/PGC0000243\", \"Sa/PGC0000639\", \"Sb/PGC0002440\", \"SBa/PGC0000635\", \"SBb/PGC0010726\", \"SBc/PGC0006826\", \"Sc/PGC0001933\"]\n",
    "for i in range(8):\n",
    "    img_path = f\"/home/chisc/workspace/wuzhenrong/galaxy/eight_type/test/{path[i]}.png\"\n",
    "    print(img_path)\n",
    "    rgb_img = cv2.imread(img_path, 1)[:, :, ::-1]   # 1 : read RGB\n",
    "    rgb_img = np.float32(rgb_img) / 255\n",
    "    input_tensor = preprocess_image(rgb_img, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])   # torch.Size([1, 3, 224, 224])\n",
    "    cam = GradCAM(model=model, target_layer=target_layer, use_cuda=False)\n",
    "    # If target_category is None, the highest scoring category\n",
    "    # will be used for every image in the batch.\n",
    "    # target_category can also be an integer, or a list of different integers\n",
    "    # for every image in the batch.\n",
    "    target_category = None # 281\n",
    "    # You can also pass aug_smooth=True and eigen_smooth=True, to apply smoothing.\n",
    "    grayscale_cam = cam(input_tensor=input_tensor, target_category=target_category, eigen_smooth=True)  # [batch, 224,224]\n",
    "    grayscale_cam = grayscale_cam[0]\n",
    "    visualization = show_cam_on_image(rgb_img, grayscale_cam)  # (224, 224, 3)\n",
    "    cv2.imwrite(f\"/home/chisc/workspace/wuzhenrong/CAM-grad/cam_dog{i}.jpg\", visualization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab32c828",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
